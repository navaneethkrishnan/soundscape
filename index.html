<!DOCTYPE html>
<html lang="ml">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Soundscape Generator & Player</title>
    <style>
        body { margin: 0; background: #121212; color: #eee; font-family: monospace; text-align: center; }
        
        /* Layout */
        .container { max-width: 800px; margin: 0 auto; padding: 10px; }
        
        /* Canvas */
        .radar-wrapper {
            position: relative;
            width: 95vw; height: 95vw;
            max-width: 500px; max-height: 500px;
            margin: 20px auto;
            border-radius: 50%;
            box-shadow: 0 0 30px rgba(0,0,0,0.8);
            background: #000;
            overflow: hidden;
            border: 2px solid #333;
        }
        canvas { width: 100%; height: 100%; display: block; }

        /* Controls */
        .controls { display: flex; gap: 10px; justify-content: center; flex-wrap: wrap; margin-bottom: 10px; }
        button {
            padding: 10px 20px; font-size: 16px; border: none; border-radius: 5px; cursor: pointer; color: white; font-weight: bold;
        }
        #recBtn { background: #e74c3c; }
        #playBtn { background: #27ae60; }
        #uploadBtn { background: #3498db; }
        
        /* File Input hidden */
        input[type="file"] { display: none; }

        /* Status */
        #status { height: 20px; color: #f39c12; margin-bottom: 5px; }
        
        /* Playback Scan Line */
        #scanLine {
            position: absolute; top: 50%; left: 50%; width: 50%; height: 2px;
            background: #fff; transform-origin: 0 0; display: none; pointer-events: none;
            box-shadow: 0 0 10px white;
        }

        /* Gallery */
        .gallery { display: flex; flex-direction: column-reverse; gap: 15px; margin-top: 20px; }
        .gallery-item img { width: 150px; border-radius: 5px; border: 1px solid #555; cursor: pointer; }
        .gallery-item { background: #222; padding: 10px; border-radius: 8px; display: flex; align-items: center; justify-content: space-between; gap: 10px; }
    </style>
</head>
<body>

<div class="container">
    <h2>Soundscape: Record & Play</h2>
    
    <div id="status">Ready. 15 Seconds Duration.</div>

    <div class="controls">
        <button id="recBtn">üî¥ Start Record (15s)</button>
        <button id="uploadBtn" onclick="document.getElementById('fileInput').click()">üìÇ Upload Image to Play</button>
        <input type="file" id="fileInput" accept="image/*">
        <button id="playBtn" style="display:none;">‚ñ∂ Play Image Sound</button>
        <button id="stopBtn" style="display:none; background:#555;">‚èπ Stop</button>
    </div>

    <div class="radar-wrapper">
        <canvas id="mainCanvas" width="1000" height="1000"></canvas>
        <div id="scanLine"></div>
    </div>

    <div class="gallery" id="gallery"></div>
</div>

<script>
    // --- CONFIGURATION ---
    const DURATION_MS = 15000; // 15 Seconds
    const SAMPLE_RATE = 20000; // Max Frequency displayed

    // --- ELEMENTS ---
    const canvas = document.getElementById('mainCanvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    const status = document.getElementById('status');
    const scanLine = document.getElementById('scanLine');
    const recBtn = document.getElementById('recBtn');
    const playBtn = document.getElementById('playBtn');
    const stopBtn = document.getElementById('stopBtn');
    
    // --- VARIABLES ---
    let audioCtx, analyser, source, stream;
    let startTime;
    let isRecording = false;
    let isPlaying = false;
    let animationId;
    let playbackOscillators = [];
    let loadedImageForPlayback = null;

    // --- INITIAL DRAW ---
    ctx.fillStyle = 'black';
    ctx.fillRect(0, 0, 1000, 1000);
    drawGrid();

    // ==========================================
    // 1. RECORDING LOGIC (GENERATOR)
    // ==========================================
    
    recBtn.onclick = async () => {
        if (isRecording) return;
        
        try {
            stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            source = audioCtx.createMediaStreamSource(stream);
            analyser = audioCtx.createAnalyser();
            
            analyser.fftSize = 4096;
            analyser.smoothingTimeConstant = 0.0; // Fast response
            source.connect(analyser);
            
            startRecording();
        } catch (e) {
            alert("Mic Access Denied: " + e.message);
        }
    };

    function startRecording() {
        isRecording = true;
        recBtn.style.display = 'none';
        status.textContent = "Recording... (15s)";
        
        // Reset Canvas
        ctx.fillStyle = 'black';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        
        // Draw Start Marker (White Line at 0 degrees)
        ctx.strokeStyle = 'white';
        ctx.lineWidth = 4;
        ctx.beginPath();
        ctx.moveTo(canvas.width/2, canvas.height/2);
        ctx.lineTo(canvas.width, canvas.height/2);
        ctx.stroke();

        startTime = performance.now();
        loopRecord();
    }

    function loopRecord() {
        if (!isRecording) return;
        
        const elapsed = performance.now() - startTime;
        const progress = elapsed / DURATION_MS;
        
        if (progress >= 1) {
            finishRecording();
            return;
        }

        requestAnimationFrame(loopRecord);

        // Calculate Angle (0 to 2*PI)
        const angle = progress * Math.PI * 2;
        
        // Get Audio Data
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        analyser.getByteFrequencyData(dataArray);

        const cx = canvas.width / 2;
        const cy = canvas.height / 2;
        const maxRadius = cx;

        ctx.save();
        ctx.translate(cx, cy);
        ctx.rotate(angle);

        // DRAWING ALGORITHM
        // We scan from center (Low Freq) to edge (High Freq)
        
        // Using Logarithmic Scale for filling the circle better with human voice
        // We skip the very first few bins (DC offset)
        const startBin = 5; 
        const endBin = bufferLength * 0.8; // Cut off extreme high freq silence
        
        for (let r = 0; r < maxRadius; r += 2) {
            // Map Radius (0 -> max) to Frequency Index (Log Scale)
            // This ensures low frequencies occupy more space in the center
            const percent = r / maxRadius;
            
            // Log mapping formula
            const logIndex = startBin + (endBin - startBin) * (Math.pow(100, percent) - 1) / 99;
            const index = Math.floor(logIndex);
            
            const value = dataArray[index] || 0;

            if (value > 10) { // Noise gate
                // Color: Violet (270) -> Red (0)
                const hue = 270 - (percent * 270);
                
                // Brightness: Based on Volume (Value)
                // If loud (255), lightness is 60%. If quiet, 10%.
                const lightness = 5 + (value / 255) * 65; 
                
                ctx.fillStyle = `hsl(${hue}, 100%, ${lightness}%)`;
                ctx.fillRect(r, -2, 4, 4); // Draw pixel
            }
        }
        ctx.restore();
    }

    function finishRecording() {
        isRecording = false;
        stream.getTracks().forEach(track => track.stop());
        status.textContent = "Recording Complete. Saving...";
        recBtn.style.display = 'inline-block';
        
        processAndSave();
    }

    function processAndSave() {
        // Add Watermark
        const now = new Date();
        const timeStr = now.toLocaleTimeString();
        
        ctx.font = "20px monospace";
        ctx.fillStyle = "white";
        ctx.textAlign = "right";
        ctx.fillText(`Soundscape | ${timeStr}`, canvas.width - 20, canvas.height - 20);

        // Save
        const url = canvas.toDataURL("image/png");
        addToGallery(url);
        
        // Load into player automatically
        loadToPlayer(url);
    }

    // ==========================================
    // 2. PLAYER LOGIC (IMAGE TO SOUND)
    // ==========================================

    document.getElementById('fileInput').onchange = function(e) {
        const file = e.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (evt) => loadToPlayer(evt.target.result);
            reader.readAsDataURL(file);
        }
    };

    function loadToPlayer(src) {
        const img = new Image();
        img.onload = () => {
            // Draw image to canvas to read pixel data
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
            loadedImageForPlayback = ctx.getImageData(0, 0, canvas.width, canvas.height);
            playBtn.style.display = 'inline-block';
            status.textContent = "Image Loaded. Ready to Play.";
        };
        img.src = src;
    }

    playBtn.onclick = () => {
        if (!loadedImageForPlayback) return;
        if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        
        isPlaying = true;
        playBtn.style.display = 'none';
        stopBtn.style.display = 'inline-block';
        scanLine.style.display = 'block';
        status.textContent = "Playing Sound from Image...";
        
        startTime = performance.now();
        playLoop();
    };

    stopBtn.onclick = () => {
        isPlaying = false;
        stopPlay();
    };

    function playLoop() {
        if (!isPlaying) return;
        
        const elapsed = performance.now() - startTime;
        let progress = (elapsed % DURATION_MS) / DURATION_MS; // Loop if needed, or stop
        
        if (elapsed > DURATION_MS) {
            stopPlay();
            return;
        }

        // Update Visual Scan Line
        const angleRad = progress * Math.PI * 2;
        const angleDeg = progress * 360;
        scanLine.style.transform = `translate(-50%, -50%) rotate(${angleDeg}deg) translate(50%, 0)`;

        // SYNTHESIZE SOUND
        synthesizeSoundAtAngle(angleRad);

        animationId = requestAnimationFrame(playLoop);
    }

    function synthesizeSoundAtAngle(angle) {
        // Clear previous oscillators to save CPU/Ears
        playbackOscillators.forEach(o => {
            o.stop();
            o.disconnect();
        });
        playbackOscillators = [];

        const cx = 500; // Canvas center (1000/2)
        const cy = 500;
        const maxR = 500;
        const pixels = loadedImageForPlayback.data;

        // We can't play every pixel (too many oscillators). We sample steps.
        const steps = 30; // Number of simultaneous tones
        
        for (let i = 1; i < steps; i++) {
            const rPercent = i / steps;
            const r = rPercent * maxR;
            
            // Find x, y at this angle and radius
            const x = Math.floor(cx + Math.cos(angle) * r);
            const y = Math.floor(cy + Math.sin(angle) * r);

            // Read Pixel Color
            if (x < 0 || x >= 1000 || y < 0 || y >= 1000) continue;
            
            const pIndex = (y * 1000 + x) * 4;
            const red = pixels[pIndex];
            const green = pixels[pIndex + 1];
            const blue = pixels[pIndex + 2];
            
            // Calculate Brightness (Volume)
            // Simple formula: Average of RGB
            const brightness = (red + green + blue) / 3;
            
            if (brightness > 30) { // If pixel is bright enough
                
                // Reconstruct Frequency (Inverse of Log Scale)
                // Roughly mapping radius back to 0-20kHz
                // Use exponential to match the recording scale
                const frequency = 50 + (Math.pow(100, rPercent) * 200); 

                // Create Oscillator
                const osc = audioCtx.createOscillator();
                const gain = audioCtx.createGain();
                
                osc.type = 'sine';
                osc.frequency.value = frequency;
                
                // Volume based on brightness (very low to avoid distortion)
                gain.gain.value = (brightness / 255) * 0.05; 

                osc.connect(gain);
                gain.connect(audioCtx.destination);
                osc.start();
                
                playbackOscillators.push(osc);
            }
        }
    }

    function stopPlay() {
        isPlaying = false;
        cancelAnimationFrame(animationId);
        playbackOscillators.forEach(o => o.stop());
        playBtn.style.display = 'inline-block';
        stopBtn.style.display = 'none';
        scanLine.style.display = 'none';
        status.textContent = "Playback Stopped.";
    }

    // --- UTILS ---
    function addToGallery(url) {
        const div = document.createElement('div');
        div.className = 'gallery-item';
        div.innerHTML = `
            <span>Recorded Image</span>
            <div>
                <a href="${url}" download="soundscape.png" style="color:#3498db; text-decoration:none;">üíæ Save</a>
                <img src="${url}" onclick="loadToPlayer(this.src)">
            </div>
        `;
        document.getElementById('gallery').prepend(div);
    }
    
    function drawGrid() {
        // Just a helper function if needed for static grid
    }

</script>

</body>
</html>
